{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "sb.set()\n",
    "from sklearn import metrics\n",
    "import missingno as msn\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "reg_data = pd.read_excel('WHR2018Chapter2OnlineData.xls',sheet_name = 'SupportingFactors')\n",
    "data = pd.read_excel('WHR2018Chapter2OnlineData.xls',sheet_name = 'Table2.1')\n",
    "region = pd.DataFrame(reg_data[[\"country\",\"Region indicator\"]])  # extracting region information from supporting factors sheet\n",
    "\n",
    "data_M = data.merge(region, on='country', how='left')         # inserting a column of region corresponding to countries to the dataset\n",
    "col = list(data_M)\n",
    "col.insert(1,col.pop(col.index('Region indicator')))\n",
    "data_M = data_M.loc[:,col]\n",
    "data_M.head(100)    # merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_M['Region indicator'].fillna(\"None\", inplace=True)\n",
    "print(\"number of regions:\",len(data_M['Region indicator'].unique())-1)    # len()-1 because \"none\" is not a region\n",
    "data_M['Region indicator'].value_counts()    # information about the regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 1, figsize=(32, 5))\n",
    "sb.countplot(data_M[\"Region indicator\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_M.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msn.matrix(data_M.sample(1562))   # visualise the locations where the values are missing\n",
    "\n",
    "msn.bar(data_M.sample(1562))    # counting the data points present for each variable in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling in the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = data_M.interpolate(method = 'linear')    # use scipy.interpolation to fill in the missing data values\n",
    "data_pred.head(1562)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msn.matrix(data_pred.sample(1562))    # some data points are still missing beacause extrapolation was not done and those points lie outside the range of given data\n",
    "\n",
    "msn.bar(data_pred.sample(1562))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation of filled-in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.pairplot(data = data_M.drop(['year'],axis=1))    #distribution of original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.pairplot(data = data_pred.drop(['year'],axis=1))    #distribution of filled in data, which should resemble that of the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete = data_pred.dropna()    # we did not use extrapolation to find the missing data points outside the range of given data points because 1.their numbers are not great and 2.their values would be more unreliable as they will be predicted from predicted values.\n",
    "data_complete.head(1562)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c = data_complete.drop(['year'],axis=1)\n",
    "f, axes = plt.subplots(1, 1, figsize=(12, 8))\n",
    "sb.heatmap(data_c.corr(), vmin = -1, vmax = 1, annot = True, fmt = \".2f\")    # look at the first column or first row to see which variable has the highest correlation coefficient with Life Ladder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='purple'>Preparation of train-test datasets</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comp = data_complete.drop(['GINI index (World Bank estimate)'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**_we are not going to use this column in building our model because the number data points given in the dataset was less than half of the number of the whole dataset and our model would be entirely based on our predicted values when we filled in the missing data points_**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comp = data_comp.drop(['Standard deviation of ladder by country-year','Standard deviation/Mean of ladder by country-year'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**_we are not going to use these columns because they are directly related/calculated from life ladder, which is the variable that we are trying to predict_**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comp1 = data_comp.drop(['year','country','Region indicator'],axis = 1).reset_index()\n",
    "\n",
    "data_comp = data_comp1.drop(['index'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**_we are not going to use these columns because they are string variables/do not have a linear relationship with life ladder_**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(data_comp['Life Ladder'])\n",
    "X = data_comp.drop(['Life Ladder'],axis = 1)    # drop life ladder becasue it is the variable we are trying to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='purple'>Linear regression model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "print(\"X_Train Set :\", X_train.shape)\n",
    "print(\"y_Train Set :\", y_train.shape)\n",
    "print(\"X_Test Set  :\", X_test.shape)\n",
    "print(\"y_Test Set  :\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "linreg.fit(X_train, y_train)    # train the model with train data\n",
    "print('Intercept of Regression \\t: b = ', linreg.intercept_)\n",
    "print('Coefficients of Regression \\t: a = ', linreg.coef_)\n",
    "print()\n",
    "pd.DataFrame(list(zip(X_train.columns, linreg.coef_[0])), columns = [\"Predictors\", \"Coefficients\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='grey'> Using cross validation to get an estimate of how well the model will do</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred_L = cross_val_predict(linreg, X, y, cv=5)    # estimate how well this model will do for predictions\n",
    "\n",
    "f, axes = plt.subplots(1, 1, figsize=(12, 12))\n",
    "plt.scatter(y, y_val_pred_L, color = \"blue\")\n",
    "plt.plot(y, y, 'w-', linewidth = 1)\n",
    "plt.xlabel(\"True values of the Response Variable (Train)\")\n",
    "plt.ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Goodness of Fit of Model \\t\")\n",
    "print(\"Score of model (R^2) \\t:\", cross_val_score(linreg, X, y, cv=5))    # R^2 values for each training and validation iteration\n",
    "print(\"Error of prediction (MSE) \\t:\", mean_squared_error(y, y_val_pred_L))\n",
    "print(\"Accuracy of prediction \\t:\", metrics.r2_score(y, y_val_pred_L))    # how well this model should do for predictions\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='grey'> Actual performance of the model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_L = linreg.predict(X_test)\n",
    "\n",
    "f, axes = plt.subplots(1, 1, figsize=(12, 12))\n",
    "plt.scatter(y_test, y_test_pred_L, color = \"green\")\n",
    "plt.plot(y_test, y_test, 'w-', linewidth = 1)\n",
    "plt.xlabel(\"True values of the Response Variable (Test)\")\n",
    "plt.ylabel(\"Predicted values of the Response Variable (Test)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Score of model (R^2) \\t:\", linreg.score(X_test, y_test))\n",
    "print(\"Erroe of prediction (MSE) \\t:\", mean_squared_error(y_test, y_test_pred_L))\n",
    "print(\"Accuracy of prediction \\t:\", metrics.r2_score(y_test, y_test_pred_L))    # how well the model actually did on the test set\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='purple'>Random forest regressor model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr.fit(X_train,y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='grey'> Using cross validation to get an estimate of how well the model will do</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_val_pred_R = cross_val_predict(rfr, X, y.values.ravel(), cv=5)    # estimate how well this model will do for predictions\n",
    "\n",
    "f, axes = plt.subplots(1, 1, figsize=(12, 12))\n",
    "plt.scatter(y, y_val_pred_R, color = \"blue\")\n",
    "plt.plot(y, y, 'w-', linewidth = 1)\n",
    "plt.xlabel(\"True values of the Response Variable (Train)\")\n",
    "plt.ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Goodness of Fit of Model \\t\")\n",
    "print(\"Score of model (R^2) \\t:\", cross_val_score(rfr, X, y.values.ravel(), cv=5))    # R^2 values for each training and validation iteration\n",
    "print(\"Error of prediction (MSE) \\t:\", mean_squared_error(y, y_val_pred_R))\n",
    "print(\"Accuracy of prediction \\t:\", metrics.r2_score(y, y_val_pred_R))    # how well this model should do for predictions\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='grey'> Actual performance of the model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_test_pred_R = rfr.predict(X_test)\n",
    "\n",
    "f, axes = plt.subplots(1, 1, figsize=(12, 12))\n",
    "plt.scatter(y_test, y_test_pred_R, color = \"green\")\n",
    "plt.plot(y_test, y_test, 'w-', linewidth = 1)\n",
    "plt.xlabel(\"True values of the Response Variable (Test)\")\n",
    "plt.ylabel(\"Predicted values of the Response Variable (Test)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Score of model (R^2) \\t:\", rfr.score(X_test, y_test))\n",
    "print(\"Erroe of prediction (MSE) \\t:\", mean_squared_error(y_test, y_test_pred_R))\n",
    "print(\"Accuracy of prediction \\t:\", metrics.r2_score(y_test, y_test_pred_R))    # how well the model actually did on the test set\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='purple'>Multi-layer perceptron regressior model</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='grey'> Data scaling</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = pd.DataFrame(scaler.transform(X_train))\n",
    "X_te = pd.DataFrame(scaler.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(y_train)\n",
    "y_tr = pd.DataFrame(scaler.transform(y_train))\n",
    "y_te = pd.DataFrame(scaler.transform(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**_Data scaling is important here to avoid exploding of gradient_**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlpr = MLPRegressor(hidden_layer_sizes=(10), activation='tanh', solver='adam',alpha=0.001,batch_size='auto',\n",
    "               learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
    "               random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9,\n",
    "               nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999,\n",
    "               epsilon=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = mlpr.fit(X_tr,y_tr.values.ravel())\n",
    "#print(reg.coefs_)\n",
    "#print(reg.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='grey'> Using cross validation to get an estimate of how well the model will do</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X)\n",
    "X_sc = pd.DataFrame(scaler.transform(X))\n",
    "scaler.fit(y)\n",
    "y_sc = pd.DataFrame(scaler.transform(y))\n",
    "\n",
    "y_val_pred_M = reg.predict(X_sc)\n",
    "\n",
    "f, axes = plt.subplots(1, 1, figsize=(12, 12))\n",
    "plt.scatter(y_sc, y_val_pred_M, color = \"blue\")\n",
    "plt.plot(y_sc, y_sc, 'w-', linewidth = 1)\n",
    "plt.xlabel(\"True values of the Response Variable (Train)\")\n",
    "plt.ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Goodness of Fit of Model \\t\")\n",
    "print(\"Score of model (R^2) \\t:\", cross_val_score(reg, X_sc, y_sc.values.ravel(), cv=5))    # R^2 values for each training and validation iteration\n",
    "print(\"Error of prediction (MSE) \\t:\", mean_squared_error(y_sc, y_val_pred_M))\n",
    "print(\"Accuracy of prediction \\t:\", metrics.r2_score(y_sc, y_val_pred_M))    # how well this model should do for predictions\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='grey'> Actual performance of the model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_M = reg.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 1, figsize=(12, 12))\n",
    "plt.scatter(y_te, y_test_pred_M, color = \"green\")\n",
    "plt.plot(y_te, y_te, 'w-', linewidth = 1)\n",
    "plt.xlabel(\"True values of the Response Variable (Train)\")\n",
    "plt.ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Score of model (R^2) \\t:\", reg.score(X_te, y_te))\n",
    "print(\"Erroe of prediction (MSE) \\t:\", mean_squared_error(y_te, y_test_pred_M))\n",
    "print(\"Accuracy of prediction \\t:\", metrics.r2_score(y_te, y_test_pred_M))    # how well the model actually did on the test set\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of 2018 Life Ladder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2018 = pd.read_excel('WHR2019Chapter2OnlineData.xls',sheet_name = 'Table2.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2018.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall = pd.DataFrame(data_2018[['Year','Country name','Life Ladder','Log GDP per capita','Social support','Healthy life expectancy at birth','Freedom to make life choices','Generosity','Perceptions of corruption','Positive affect','Negative affect','Confidence in national government','Democratic Quality','Delivery Quality','Standard deviation of ladder by country-year','Standard deviation/Mean of ladder by country-year','GINI index (World Bank estimate)','GINI index (World Bank estimate), average 2000-16','gini of household income reported in Gallup, by wp5-year']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msn.matrix(overall.sample(1704))\n",
    "msn.bar(overall.sample(1704))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2018 = overall.interpolate(method = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msn.matrix(pred_2018.sample(1704))\n",
    "msn.bar(pred_2018.sample(1704))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2018 = pred_2018.dropna()\n",
    "pred_2018 = pred_2018.drop(['GINI index (World Bank estimate)'],axis = 1)\n",
    "pred_2018 = pred_2018.drop(['Standard deviation of ladder by country-year','Standard deviation/Mean of ladder by country-year'],axis = 1)\n",
    "pred_2018 = pred_2018.drop(['Country name'],axis = 1)\n",
    "\n",
    "pred_2018.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_2018 = pred_2018[pred_2018[\"Year\"] == 2018]\n",
    "year_2018 = year_2018.drop(['Year'],axis = 1).reset_index()\n",
    "year_2018 = year_2018.drop(['index'],axis = 1)\n",
    "year_2018.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_2018.head(135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2018 = pd.DataFrame(year_2018['Life Ladder'])\n",
    "X_2018 = year_2018.drop(['Life Ladder'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2018_pred_L = linreg.predict(X_2018)\n",
    "y_2018_pred_R = rfr.predict(X_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X_2018)    # Data scaling for MLPRegressor\n",
    "X_M_2018 = pd.DataFrame(scaler.transform(X_2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(y_2018)    # Data scaling for MLPRegressor\n",
    "y_M_2018 = pd.DataFrame(scaler.transform(y_2018))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2018_pred_M = reg.predict(X_M_2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 3, figsize=(24, 6))\n",
    "axes[0].scatter(y_2018, y_2018_pred_L, color = \"blue\")\n",
    "axes[0].plot(y_2018, y_2018, 'w-', linewidth = 1)\n",
    "axes[0].set_xlabel(\"True values of the Response Variable\")\n",
    "axes[0].set_ylabel(\"Predicted values of the Response Variable\")\n",
    "\n",
    "axes[1].scatter(y_2018, y_2018_pred_R, color = \"green\")\n",
    "axes[1].plot(y_2018, y_2018, 'w-', linewidth = 1)\n",
    "axes[1].set_xlabel(\"True values of the Response Variable\")\n",
    "axes[1].set_ylabel(\"Predicted values of the Response Variable\")\n",
    "\n",
    "axes[2].scatter(y_M_2018, y_2018_pred_M, color = \"red\")\n",
    "axes[2].plot(y_M_2018, y_M_2018, 'w-', linewidth = 1)\n",
    "axes[2].set_xlabel(\"True values of the Response Variable\")\n",
    "axes[2].set_ylabel(\"Predicted values of the Response Variable\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Goodness of Fit of Linear Regression Model \\t\")\n",
    "print(\"Score of the model (R^2) \\t:\", linreg.score(X_2018, y_2018))\n",
    "print(\"Error of prediction (MSE) \\t:\", mean_squared_error(y_2018, y_2018_pred_L))\n",
    "print(\"Accuracy of prediction:\", metrics.r2_score(y_2018, y_2018_pred_L))\n",
    "print()\n",
    "\n",
    "print(\"Goodness of Fit of Random Forest Regressor Model \\t\")\n",
    "print(\"Score of model (R^2) \\t:\", rfr.score(X_2018, y_2018))\n",
    "print(\"Erroe of prediction (MSE) \\t:\", mean_squared_error(y_2018, y_2018_pred_R))\n",
    "print(\"Accuracy of prediction \\t:\", metrics.r2_score(y_2018, y_2018_pred_R))\n",
    "print()\n",
    "\n",
    "print(\"Goodness of Fit of Linear Regression Model \\t\")\n",
    "print(\"Score of the model (R^2) \\t:\", reg.score(X_M_2018, y_M_2018))\n",
    "print(\"Error of prediction (MSE) \\t:\", mean_squared_error(y_M_2018, y_2018_pred_M))\n",
    "print(\"Accuracy of prediction:\", metrics.r2_score(y_M_2018, y_2018_pred_M))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the scores obtained from cross validation and those from the prediction for the test datasets, MLPRegressor and random forest regressor have the higher scores and accuracies than the linear regression model, and hence would be the best model for Life Ladder predictions in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
