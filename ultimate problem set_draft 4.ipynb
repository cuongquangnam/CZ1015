{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "sb.set()\n",
    "from sklearn import metrics\n",
    "import missingno as msn\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "reg_data = pd.read_excel('WHR2018Chapter2OnlineData.xls',sheet_name = 'SupportingFactors')\n",
    "data = pd.read_excel('WHR2018Chapter2OnlineData.xls',sheet_name = 'Table2.1')\n",
    "region = pd.DataFrame(reg_data[[\"country\",\"Region indicator\"]])  # extracting region information from supporting factors sheet\n",
    "\n",
    "data_M = data.merge(region, on='country', how='left')         # inserting a column of region corresponding to countries to the dataset\n",
    "col = list(data_M)\n",
    "col.insert(1,col.pop(col.index('Region indicator')))\n",
    "data_M = data_M.loc[:,col]\n",
    "data_M.head(100)    # merged data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_M['Region indicator'].fillna(\"None\", inplace=True)\n",
    "print(\"number of regions:\",len(data_M['Region indicator'].unique())-1)    # len()-1 because \"none\" is not a region\n",
    "data_M['Region indicator'].value_counts()    # information about the regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 1, figsize=(32, 5))\n",
    "sb.countplot(data_M[\"Region indicator\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_M.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msn.matrix(data_M.sample(1562))   # visualise the locations where the values are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msn.bar(data_M.sample(1562))    # counting the data points present for each variable in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filling in the missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred = data_M.interpolate(method = 'linear')    # use scipy.interpolation to fill in the missing data values\n",
    "data_pred.head(1562)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pred.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msn.matrix(data_pred.sample(1562))    # some data points are still missing beacause extrapolation was not done and those points lie outside the range of given data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msn.bar(data_pred.sample(1562))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation of filled-in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.pairplot(data = data_M.drop(['year'],axis=1))    #distribution of original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.pairplot(data = data_pred.drop(['year'],axis=1))    #distribution of filled in data, which should resemble that of the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete = data_pred.dropna()    # we did not use extrapolation to find the missing data points outside the range of given data points because 1.their numbers are not great and 2.their values would be more unreliable as they will be predicted from predicted values.\n",
    "data_complete.head(1562)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_complete.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_c = data_complete.drop(['year'],axis=1)\n",
    "f, axes = plt.subplots(1, 1, figsize=(12, 8))\n",
    "sb.heatmap(data_c.corr(), vmin = -1, vmax = 1, annot = True, fmt = \".2f\")    # look at the first column or first row to see which variable has the highest correlation coefficient with Life Ladder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='grey'>Preparation of train-test datasets</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comp = data_complete.drop(['GINI index (World Bank estimate)'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**_we are not going to use this column in building our model because the number data points given in the dataset was less than half of the number of the whole dataset and our model would be entirely based on our predicted values when we filled in the missing data points_**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comp = data_comp.drop(['Standard deviation of ladder by country-year','Standard deviation/Mean of ladder by country-year'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**_we are not going to use these columns because they are directly related/calculated from life ladder, which is the variable that we are trying to predict_**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comp1 = data_comp.drop(['year','country','Region indicator'],axis = 1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comp = data_comp1.drop(['index'],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>**_we are not going to use these columns because they are string variables/do not have a linear relationship with life ladder_**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_comp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(data_comp['Life Ladder'])\n",
    "X = data_comp.drop(['Life Ladder'],axis = 1)    # drop life ladder becasue it is the variable we are trying to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='yellow'>Hold-out validation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_h, X_test_h, y_train_h, y_test_h = train_test_split(X, y, test_size = 0.2)\n",
    "\n",
    "print(\"X_Train Set :\", X_train_h.shape)\n",
    "print(\"X_Test Set  :\", X_test_h.shape)\n",
    "print(\"y_Train Set :\", y_train_h.shape)\n",
    "print(\"y_Test Set  :\", y_test_h.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='yellow'>Cross-validation (K-fold)</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=6)\n",
    "kf.get_n_splits(X) # returns the number of splitting iterations in the cross-validator\n",
    "print(kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in kf.split(X,y):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train_cv, X_test_cv = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train_cv, y_test_cv = y.iloc[train_index], y.iloc[test_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='grey'>Linear regression model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "linreg_h = LinearRegression()\n",
    "linreg_cv = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='purple'> Using hold-out validation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "linreg_h.fit(X_train_h, y_train_h)\n",
    "print('Intercept of Regression \\t: b = ', linreg_h.intercept_)\n",
    "print('Coefficients of Regression \\t: a = ', linreg_h.coef_)\n",
    "print()\n",
    "pd.DataFrame(list(zip(X_train_h.columns, linreg_h.coef_[0])), columns = [\"Predictors\", \"Coefficients\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_h_pred_L = linreg_h.predict(X_train_h)\n",
    "y_test_h_pred_L = linreg_h.predict(X_test_h)\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train_h, y_train_h_pred_L, color = \"blue\")\n",
    "axes[0].plot(y_train_h, y_train_h, 'w-', linewidth = 1)\n",
    "axes[0].set_xlabel(\"True values of the Response Variable (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "axes[1].scatter(y_test_h, y_test_h_pred_L, color = \"green\")\n",
    "axes[1].plot(y_test_h, y_test_h, 'w-', linewidth = 1)\n",
    "axes[1].set_xlabel(\"True values of the Response Variable (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values of the Response Variable (Test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Score of model (R^2) \\t:\", linreg_h.score(X_train_h, y_train_h))\n",
    "print(\"Error of prediction (MSE) \\t:\", mean_squared_error(y_train_h, y_train_h_pred_L))\n",
    "print(\"Accuracy of prediction \\t:\", metrics.r2_score(y_train_h, y_train_h_pred_L))\n",
    "print()\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Score of model (R^2) \\t:\", linreg_h.score(X_test_h, y_test_h))\n",
    "print(\"Erroe of prediction (MSE) \\t:\", mean_squared_error(y_test_h, y_test_h_pred_L))\n",
    "print(\"Accuracy of prediction \\t:\", metrics.r2_score(y_test_h, y_test_h_pred_L))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='purple'> Using cross validation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_cv.fit(X_train_cv, y_train_cv)\n",
    "print('Intercept of Regression \\t: b = ', linreg_cv.intercept_)\n",
    "print('Coefficients of Regression \\t: a = ', linreg_cv.coef_)\n",
    "print()\n",
    "pd.DataFrame(list(zip(X_train_cv.columns, linreg_cv.coef_[0])), columns = [\"Predictors\", \"Coefficients\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cv_pred_L = cross_val_predict(linreg_cv, X_train_cv, y_train_cv, cv=6)\n",
    "y_test_cv_pred_L = cross_val_predict(linreg_cv, X_test_cv, y_test_cv, cv=6)\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train_cv, y_train_cv_pred_L, color = \"blue\")\n",
    "axes[0].plot(y_train_cv, y_train_cv, 'w-', linewidth = 1)\n",
    "axes[0].set_xlabel(\"True values of the Response Variable (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "axes[1].scatter(y_test_cv, y_test_cv_pred_L, color = \"green\")\n",
    "axes[1].plot(y_test_cv, y_test_cv, 'w-', linewidth = 1)\n",
    "axes[1].set_xlabel(\"True values of the Response Variable (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values of the Response Variable (Test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Score of model (R^2) \\t:\", cross_val_score(linreg_cv, X_train_cv, y_train_cv, cv=6))\n",
    "print(\"Error of prediction (MSE) \\t:\", mean_squared_error(y_train_cv, y_train_cv_pred_L))\n",
    "print(\"Accuracy of prediction \\t:\", metrics.r2_score(y_train_cv, y_train_cv_pred_L))\n",
    "print()\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Score of model (R^2) \\t:\", cross_val_score(linreg_cv, X_test_cv, y_test_cv, cv=6))\n",
    "print(\"Erroe of prediction (MSE) \\t:\", mean_squared_error(y_test_cv, y_test_cv_pred_L))\n",
    "print(\"Accuracy of prediction \\t:\", metrics.r2_score(y_test_cv, y_test_cv_pred_L))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='grey'>Random forest regressor model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr_h = RandomForestRegressor()\n",
    "rfr_cv = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='purple'> Using hold-out validation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_h.fit(X_train_h,y_train_h.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_h_pred_R = rfr_h.predict(X_train_h)\n",
    "y_test_h_pred_R = rfr_h.predict(X_test_h)\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train_h, y_train_h_pred_R, color = \"blue\")\n",
    "axes[0].plot(y_train_h, y_train_h, 'w-', linewidth = 1)\n",
    "axes[0].set_xlabel(\"True values of the Response Variable (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "axes[1].scatter(y_test_h, y_test_h_pred_R, color = \"green\")\n",
    "axes[1].plot(y_test_h, y_test_h, 'w-', linewidth = 1)\n",
    "axes[1].set_xlabel(\"True values of the Response Variable (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values of the Response Variable (Test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Score of the model (R^2) \\t:\", rfr_h.score(X_train_h, y_train_h))\n",
    "print(\"Error of prediction (MSE) \\t:\", mean_squared_error(y_train_h, y_train_h_pred_R))\n",
    "print(\"Accuracy of prediction:\", metrics.r2_score(y_train_h, y_train_h_pred_R))\n",
    "print()\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Score of the model (R^2) \\t:\", rfr_h.score(X_test_h, y_test_h))\n",
    "print(\"Error of prediction (MSE) \\t:\", mean_squared_error(y_test_h, y_test_h_pred_R))\n",
    "print(\"Accuracy of prediction:\", metrics.r2_score(y_test_h, y_test_h_pred_R))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='purple'> Using cross validation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_cv.fit(X_train_cv,y_train_cv.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_cv_pred_R = cross_val_predict(rfr_cv, X_train_cv, y_train_cv.values.ravel(), cv=6)\n",
    "y_test_cv_pred_R = cross_val_predict(rfr_cv, X_test_cv, y_test_cv.values.ravel(), cv=6)\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "axes[0].scatter(y_train_cv, y_train_cv_pred_R, color = \"blue\")\n",
    "axes[0].plot(y_train_cv, y_train_cv, 'w-', linewidth = 1)\n",
    "axes[0].set_xlabel(\"True values of the Response Variable (Train)\")\n",
    "axes[0].set_ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "axes[1].scatter(y_test_cv, y_test_cv_pred_R, color = \"green\")\n",
    "axes[1].plot(y_test_cv, y_test_cv, 'w-', linewidth = 1)\n",
    "axes[1].set_xlabel(\"True values of the Response Variable (Test)\")\n",
    "axes[1].set_ylabel(\"Predicted values of the Response Variable (Test)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Goodness of Fit of Model \\tTrain Dataset\")\n",
    "print(\"Score of model (R^2) \\t:\", cross_val_score(rfr_cv, X_train_cv, y_train_cv.values.ravel(), cv=6))\n",
    "print(\"Error of prediction (MSE) \\t:\", mean_squared_error(y_train_cv, y_train_cv_pred_R))\n",
    "print(\"Accuracy of prediction \\t:\", metrics.r2_score(y_train_cv, y_train_cv_pred_R))\n",
    "print()\n",
    "print(\"Goodness of Fit of Model \\tTest Dataset\")\n",
    "print(\"Score of model (R^2) \\t:\", cross_val_score(rfr_cv, X_test_cv, y_test_cv.values.ravel(), cv=6))\n",
    "print(\"Erroe of prediction (MSE) \\t:\", mean_squared_error(y_test_cv, y_test_cv_pred_R))\n",
    "print(\"Accuracy of prediction \\t:\", metrics.r2_score(y_test_cv, y_test_cv_pred_R))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction of 2019 Life Ladder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2019 = pd.read_excel('WHR2019Chapter2OnlineData.xls',sheet_name = 'Table2.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2019.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall = pd.DataFrame(data_2019[['Year','Country name','Life Ladder','Log GDP per capita','Social support','Healthy life expectancy at birth','Freedom to make life choices','Generosity','Perceptions of corruption','Positive affect','Negative affect','Confidence in national government','Democratic Quality','Delivery Quality','Standard deviation of ladder by country-year','Standard deviation/Mean of ladder by country-year','GINI index (World Bank estimate)','GINI index (World Bank estimate), average 2000-16','gini of household income reported in Gallup, by wp5-year']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msn.matrix(overall.sample(1704))\n",
    "msn.bar(overall.sample(1704))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2019 = overall.interpolate(method = 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msn.matrix(pred_2019.sample(1704))\n",
    "msn.bar(pred_2019.sample(1704))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2019 = pred_2019.dropna()\n",
    "pred_2019 = pred_2019.drop(['GINI index (World Bank estimate)'],axis = 1)\n",
    "pred_2019 = pred_2019.drop(['Standard deviation of ladder by country-year','Standard deviation/Mean of ladder by country-year'],axis = 1)\n",
    "pred_2019_1 = pred_2019.drop(['Year','Country name'],axis = 1).reset_index()\n",
    "pred_2019 = pred_2019_1.drop(['index'],axis = 1)\n",
    "y_2019 = pd.DataFrame(pred_2019['Life Ladder'])\n",
    "X_2019 = pred_2019.drop(['Life Ladder'],axis = 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_2019.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_2019_h_pred_L = linreg_h.predict(X_2019)\n",
    "y_2019_cv_pred_L = cross_val_predict(linreg_cv, X_2019, y_2019, cv=6)\n",
    "y_2019_h_pred_R = rfr_h.predict(X_2019)\n",
    "y_2019_cv_pred_R = cross_val_predict(rfr_cv, X_2019, y_2019.values.ravel(), cv=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, axes = plt.subplots(1, 4, figsize=(24, 6))\n",
    "axes[0].scatter(y_2019, y_2019_h_pred_L, color = \"blue\")\n",
    "axes[0].plot(y_2019, y_2019, 'w-', linewidth = 1)\n",
    "axes[0].set_xlabel(\"True values of the Response Variable\")\n",
    "axes[0].set_ylabel(\"Predicted values of the Response Variable\")\n",
    "\n",
    "axes[1].scatter(y_2019, y_2019_cv_pred_L, color = \"green\")\n",
    "axes[1].plot(y_2019, y_2019, 'w-', linewidth = 1)\n",
    "axes[1].set_xlabel(\"True values of the Response Variable\")\n",
    "axes[1].set_ylabel(\"Predicted values of the Response Variable\")\n",
    "\n",
    "axes[2].scatter(y_2019, y_2019_h_pred_R, color = \"green\")\n",
    "axes[2].plot(y_2019, y_2019, 'w-', linewidth = 1)\n",
    "axes[2].set_xlabel(\"True values of the Response Variable\")\n",
    "axes[2].set_ylabel(\"Predicted values of the Response Variable\")\n",
    "\n",
    "axes[3].scatter(y_2019, y_2019_cv_pred_R, color = \"green\")\n",
    "axes[3].plot(y_2019, y_2019, 'w-', linewidth = 1)\n",
    "axes[3].set_xlabel(\"True values of the Response Variable\")\n",
    "axes[3].set_ylabel(\"Predicted values of the Response Variable\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Goodness of Fit of Model 1 \\t\")    # model 1 is using the linear regression model trained with hold-out validation\n",
    "print(\"Score of the model (R^2) \\t:\", linreg_h.score(X_train_h, y_train_h))\n",
    "print(\"Error of prediction (MSE) \\t:\", mean_squared_error(y_2019, y_2019_h_pred_L))\n",
    "print(\"Accuracy of prediction:\", metrics.r2_score(y_2019, y_2019_h_pred_L))\n",
    "print()\n",
    "\n",
    "print(\"Goodness of Fit of Model 2 \\t\")    # model 2 is using the linear regression model trained with cross validation\n",
    "print(\"Score of model (R^2) \\t:\", cross_val_score(linreg_cv, X_train_cv, y_train_cv, cv=6))\n",
    "print(\"Erroe of prediction (MSE) \\t:\", mean_squared_error(y_2019, y_2019_cv_pred_L))\n",
    "print(\"Accuracy of prediction \\t:\", metrics.r2_score(y_2019, y_2019_cv_pred_L))\n",
    "print()\n",
    "\n",
    "print(\"Goodness of Fit of Model 3 \\t\")    # model 3 is using the random forest regressor model trained with hold-out validation\n",
    "print(\"Score of the model (R^2) \\t:\", rfr_h.score(X_train_h, y_train_h.values.ravel()))\n",
    "print(\"Error of prediction (MSE) \\t:\", mean_squared_error(y_2019, y_2019_h_pred_R))\n",
    "print(\"Accuracy of prediction:\", metrics.r2_score(y_2019, y_2019_h_pred_R))\n",
    "print()\n",
    "\n",
    "print(\"Goodness of Fit of Model 4 \\t\")    # model 4 is using the random forest regressor model trained with cross validation\n",
    "print(\"Score of model (R^2) \\t:\", cross_val_score(rfr_cv, X_train_cv, y_train_cv.values.ravel(), cv=6))\n",
    "print(\"Error of prediction (MSE) \\t:\", mean_squared_error(y_2019, y_2019_cv_pred_R))\n",
    "print(\"Accuracy of prediction \\t:\", metrics.r2_score(y_2019, y_2019_cv_pred_R))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
